{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Gran Dalmuti - QLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic game mechanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CARD_VALUES = 13\n",
    "JOKER = 12  # Jokers at index 12\n",
    "\n",
    "\n",
    "def has_already_won(hand):\n",
    "    \"\"\"\n",
    "    hand - vector with 13 entries (number of 1, 2, ..., 12, Jokers)\n",
    "    \"\"\"\n",
    "\n",
    "    if len(hand.shape) == 1:\n",
    "        return np.all(hand == 0)\n",
    "    else:\n",
    "        return np.all(hand == 0, axis=1)\n",
    "    \n",
    "    \n",
    "def get_cards_array(card_type, num_cards):\n",
    "    \"\"\" Vector representation of the cards of one kind. \"\"\"\n",
    "    \n",
    "    cards_array = np.zeros(NUM_CARD_VALUES, dtype=np.int8)\n",
    "    cards_array[card_type] = num_cards\n",
    "    return cards_array\n",
    "    \n",
    "\n",
    "def possible_next_moves(hand, board):\n",
    "    \"\"\"\n",
    "    Returns possible next moves as a list of tuples (new hand, new board)\n",
    "    \"\"\"\n",
    "    \n",
    "    card_type_in_board = np.argmax(board)\n",
    "    num_cards_in_board = board[card_type_in_board] + board[JOKER]\n",
    "    \n",
    "    # You can always pass if it is not the initial move\n",
    "    possible_hands = np.reshape(hand, (1, NUM_CARD_VALUES))\n",
    "    possible_boards = np.reshape(board, (1, NUM_CARD_VALUES))\n",
    "    \n",
    "    if not has_already_won(hand):\n",
    "        for card_type_in_hand in range(NUM_CARD_VALUES - 1, -1, -1):\n",
    "            # You can play clean\n",
    "            if card_type_in_hand < card_type_in_board and \\\n",
    "              hand[card_type_in_hand] >= num_cards_in_board:\n",
    "                new_board = get_cards_array(card_type_in_hand, num_cards_in_board)\n",
    "                new_hand = hand - new_board\n",
    "                possible_hands = np.vstack([possible_hands, new_hand])\n",
    "                possible_boards = np.vstack([possible_boards, new_board])\n",
    "\n",
    "            # Or you can play dirty (with Joker(s))\n",
    "            if card_type_in_hand != JOKER and hand[JOKER] > 0 and \\\n",
    "              card_type_in_hand < card_type_in_board and hand[card_type_in_hand] > 0 and \\\n",
    "              hand[card_type_in_hand] + hand[JOKER] >= num_cards_in_board:\n",
    "                # Use one joker\n",
    "                if hand[card_type_in_hand] + 1 >= num_cards_in_board:\n",
    "                    joker_vec = get_cards_array(JOKER, 1)\n",
    "                    new_board = get_cards_array(card_type_in_hand, num_cards_in_board - 1) + joker_vec\n",
    "                    new_hand = hand - new_board\n",
    "                    possible_hands = np.vstack([possible_hands, new_hand])\n",
    "                    possible_boards = np.vstack([possible_boards, new_board])\n",
    "\n",
    "                # Use two jokers\n",
    "                if hand[JOKER] == 2 and num_cards_in_board > 2:\n",
    "                    joker_vec = get_cards_array(JOKER, 2)\n",
    "                    new_board = get_cards_array(card_type_in_hand, num_cards_in_board - 2) + joker_vec\n",
    "                    new_hand = hand - new_board\n",
    "                    possible_hands = np.vstack([possible_hands, new_hand])\n",
    "                    possible_boards = np.vstack([possible_boards, new_board])\n",
    "            \n",
    "    return possible_hands, possible_boards\n",
    "        \n",
    "    \n",
    "# Some tests\n",
    "assert has_already_won(np.zeros(NUM_CARD_VALUES))\n",
    "assert not has_already_won(np.ones(NUM_CARD_VALUES))\n",
    "assert np.all(has_already_won(np.zeros((2, NUM_CARD_VALUES))) == np.array([True, True]))\n",
    "assert np.all(has_already_won(np.array([[0,0,0,0,1], [0,0,0,0,0], [1,0,0,0,0]])) == np.array([False, True, False]))\n",
    "\n",
    "assert np.all(get_cards_array(1, 2) == np.array([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
    "assert np.all(get_cards_array(4, 3) == np.array([0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
    "assert not np.all(get_cards_array(4, 3) == np.array([0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
    "\n",
    "# Tests for possible moves\n",
    "h, b = possible_next_moves(np.array([0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2]),\n",
    "                           np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0]))\n",
    "assert np.all(h == np.array([[0., 2., 0., 0., 0., 0., 0., 2., 0., 2., 0., 0., 2.],\n",
    "                             [0., 2., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 2.],\n",
    "                             [0., 2., 0., 0., 0., 0., 0., 1., 0., 2., 0., 0., 1.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 2., 0., 2., 0., 0., 2.],\n",
    "                             [0., 1., 0., 0., 0., 0., 0., 2., 0., 2., 0., 0., 1.]]))\n",
    "assert np.all(b == np.array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
    "                             [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                             [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]))\n",
    "h, b = possible_next_moves(np.array([1, 2, 3, 1, 0, 0, 0, 3, 0, 4, 0, 0, 2]),\n",
    "                           np.array([0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1]))\n",
    "assert np.all(h == np.array([[1., 2., 3., 1., 0., 0., 0., 3., 0., 4., 0., 0., 2.],\n",
    "                             [1., 2., 3., 1., 0., 0., 0., 0., 0., 4., 0., 0., 2.],\n",
    "                             [1., 2., 3., 1., 0., 0., 0., 1., 0., 4., 0., 0., 1.],\n",
    "                             [1., 2., 3., 1., 0., 0., 0., 2., 0., 4., 0., 0., 0.],\n",
    "                             [1., 2., 3., 0., 0., 0., 0., 3., 0., 4., 0., 0., 0.],\n",
    "                             [1., 2., 0., 1., 0., 0., 0., 3., 0., 4., 0., 0., 2.],\n",
    "                             [1., 2., 1., 1., 0., 0., 0., 3., 0., 4., 0., 0., 1.],\n",
    "                             [1., 2., 2., 1., 0., 0., 0., 3., 0., 4., 0., 0., 0.],\n",
    "                             [1., 0., 3., 1., 0., 0., 0., 3., 0., 4., 0., 0., 1.],\n",
    "                             [1., 1., 3., 1., 0., 0., 0., 3., 0., 4., 0., 0., 0.],\n",
    "                             [0., 2., 3., 1., 0., 0., 0., 3., 0., 4., 0., 0., 0.]]))\n",
    "assert np.all(b == np.array([[0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0., 0.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 2.],\n",
    "                             [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 2.],\n",
    "                             [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                             [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                             [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.],\n",
    "                             [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                             [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.],\n",
    "                             [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h, b = possible_next_moves(np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 2]),\n",
    "                           np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]))\n",
    "len(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Random Initial Game States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 2, 3, 2, 0, 3, 2, 1, 3, 1, 1],\n",
       "       [0, 1, 0, 0, 1, 2, 1, 2, 3, 4, 2, 4, 0],\n",
       "       [1, 0, 1, 1, 0, 1, 3, 1, 1, 4, 1, 5, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 3, 2, 3, 1, 5, 2, 0]], dtype=int8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_PLAYERS = 4\n",
    "AVAILABLE_CARDS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 2]\n",
    "PLAYER = list(range(NUM_PLAYERS))\n",
    "\n",
    "\n",
    "def random_initial_cards():\n",
    "    \"\"\" Random initial state for the game. \"\"\"\n",
    "    \n",
    "    deck = np.array([], dtype=np.int8)\n",
    "\n",
    "    for card_type in range(NUM_CARD_VALUES):\n",
    "        deck = np.append(deck, np.array([card_type for _ in range(AVAILABLE_CARDS[card_type])]))\n",
    "    \n",
    "    np.random.shuffle(deck)\n",
    "    \n",
    "    chunk = deck.shape[0] // NUM_PLAYERS\n",
    "    remainder = deck.shape[0] % NUM_PLAYERS\n",
    "    first_player_initialized = False\n",
    "    \n",
    "    for playerIndex in range(NUM_PLAYERS):\n",
    "        beginOfChunk = playerIndex * chunk + min(playerIndex, remainder)\n",
    "        endOfChunk = (playerIndex + 1) * chunk + min(playerIndex + 1, remainder)\n",
    "        player = np.zeros(NUM_CARD_VALUES, dtype=np.int8)\n",
    "        \n",
    "        for card in deck[beginOfChunk:endOfChunk]:\n",
    "            player += get_cards_array(card, 1)\n",
    "            \n",
    "        if first_player_initialized:\n",
    "            player_initial_hands = np.vstack([player_initial_hands, player])\n",
    "        else:\n",
    "            first_player_initialized = True\n",
    "            player_initial_hands = player\n",
    "        \n",
    "    return player_initial_hands\n",
    "        \n",
    "        \n",
    "random_initial_cards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(random_initial_cards(), axis=1) == 20 * np.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.sum(random_initial_cards(), axis=1) == 20 * np.ones(NUM_PLAYERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Cards Vector for Indexing and Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_bit_offset = [\n",
    "      0,  2,  6, 10, 14, 18,  22,  25,  28,  31,  34,  36,  38,\n",
    "     39, 41, 45, 49, 53, 57,  61,  64,  67,  70,  73,  75,  77,\n",
    "     78, 80, 84, 88, 92, 96, 100, 103, 106, 109, 112, 114, 116,\n",
    "    117  # sentinel\n",
    "]\n",
    "\n",
    "def encode_card_array(card_array):\n",
    "    \"\"\"\n",
    "    Encodes a card vector into an int64.\n",
    "    | Board | Hand | Already played |\n",
    "     38   26 25  13 12             0\n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def decode_card_repr(card_repr):\n",
    "    \"\"\"\n",
    "    Decodes an int64 back to a card vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Learning\n",
    "alpha = 0.8\n",
    "gamma = 1.0\n",
    "epsilon = 0.1\n",
    "\n",
    "debug = False\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_wins = []\n",
    "\n",
    "player1States = np.array([np.zeros(9, dtype=int)])\n",
    "player1QTable = np.array([np.zeros(9)])\n",
    "player1 = 1\n",
    "\n",
    "player2States = np.array([np.zeros(9, dtype=int)])\n",
    "player2QTable = np.array([np.zeros(9)])\n",
    "player2 = -1\n",
    "\n",
    "def step(player, player_states, player_table, player_state, iterations=0, best=False):\n",
    "    if debug:\n",
    "        print(\"Player\", player, \"- State\", player_state)\n",
    "    \n",
    "    # Possible actions\n",
    "    actions_possible = (player_state == 0)\n",
    "    \n",
    "    # Exit if board full\n",
    "    if not np.any(actions_possible):\n",
    "        return True, player_states, player_table, player_state\n",
    "    \n",
    "    # Retrieve Q-Table for current state\n",
    "    learned_values = player_table[np.all(player_states == player_state, axis=1)]\n",
    "\n",
    "    # Add new Q-Table entry if necessary\n",
    "    if learned_values.size > 0:\n",
    "        learned_values = learned_values[0]\n",
    "    else:\n",
    "        learned_values = np.zeros(9, dtype=int)\n",
    "        player_states = np.vstack((player_states, np.reshape(player_state, (1,9))))\n",
    "        player_table = np.vstack((player_table, np.reshape(learned_values, (1,9))))\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Player\", player, \"- Learned Values\", learned_values)\n",
    "    \n",
    "    # Decrease random decisions with increasing knowledge\n",
    "    if not best and np.random.uniform() < (epsilon / min(1, (iterations / 20000))):\n",
    "        # Random choice among possible actions\n",
    "        action = np.random.choice(np.nonzero(actions_possible)[0])\n",
    "    else:\n",
    "        # Get best action\n",
    "        possible_qvalues = np.where(actions_possible, learned_values, np.nan)\n",
    "        action = np.random.choice(np.flatnonzero(np.isclose(\n",
    "            possible_qvalues, np.nanmax(possible_qvalues))))\n",
    "        \n",
    "    # Next state\n",
    "    next_state = np.where(np.arange(9) == action, player, player_state)\n",
    "    \n",
    "    # Old value\n",
    "    old_value = learned_values[action]\n",
    "    \n",
    "    # Next maximum value\n",
    "    if debug:\n",
    "        print(\"Player\", player, \"- Player States\", player_states)\n",
    "        print(\"Player\", player, \"- Next State\", next_state)\n",
    "        print(\"Player\", player, \"- QTable\", player_table)\n",
    "    actions_possible_in_next_state = (next_state == 0)\n",
    "    next_qvalues = player_table[np.all(player_states == next_state, axis=1)]\n",
    "    next_max = np.nanmax(np.where(actions_possible_in_next_state, next_qvalues[0], np.nan)) \\\n",
    "        if next_qvalues.size > 0 else 0\n",
    "\n",
    "    # Determine reward\n",
    "    if almost_complete(next_state, -player):\n",
    "        reward_earned = -1  # Penalty if other player can win game next turn\n",
    "    elif reward(next_state, player):\n",
    "        reward_earned = 1\n",
    "    else:\n",
    "        reward_earned = 0\n",
    "    \n",
    "    # Determine new value\n",
    "    new_value = (1 - alpha) * old_value + alpha * (reward_earned + gamma * next_max)\n",
    "    learned_values[action] = new_value\n",
    "    player_table[np.all(player_states == player_state, axis=1)] = learned_values\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Player\", player, \"- QTable updated\", player_table)\n",
    "    \n",
    "    # Return next state\n",
    "    return (reward_earned == 1), player_states, player_table, next_state\n",
    "    \n",
    "\n",
    "last_iteration = 100001\n",
    "    \n",
    "for i in range(1, last_iteration + 1):\n",
    "    epochs = 0\n",
    "    \n",
    "    current_state = np.zeros(9, dtype=int)\n",
    "    \n",
    "    while True:\n",
    "        done, player1States, player1QTable, current_state = step(\n",
    "            player1, player1States, player1QTable, current_state, i)\n",
    "        \n",
    "        if i == last_iteration:\n",
    "            print(\"Player 1\")\n",
    "            print_board(current_state)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        done, player2States, player2QTable, current_state = step(\n",
    "            player2, player2States, player2QTable, current_state, i)\n",
    "        \n",
    "        if i == last_iteration:\n",
    "            print(\"Player 2\")\n",
    "            print_board(current_state)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        epochs += 1\n",
    "            \n",
    "    all_epochs.append(epochs)\n",
    "    all_wins.append(current_state)\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Episode:\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d1a980fe12b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "a = { np.array([1,0,2,12]): (12, np.array([1,0,2,12])), np.array([1,0,1,12]): (10, np.array([1,0,1,12])) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66555937033867822607895549241096482953017615834735226163,\n",
       " 18446744073709551616,\n",
       " False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "(3 ** 117), (2 ** 64), (3 ** 117) < (2 ** 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4052555153018976267"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int64(3 ** 39)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
