{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Gran Dalmuti - QLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic game mechanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CARD_VALUES = 13\n",
    "JOKER = 12  # Jokers at index 12\n",
    "\n",
    "\n",
    "def has_already_won(hand):\n",
    "    \"\"\"\n",
    "    hand - vector with 13 entries (number of 1, 2, ..., 12, Jokers)\n",
    "    \"\"\"\n",
    "\n",
    "    if len(hand.shape) == 1:\n",
    "        return np.all(hand == 0)\n",
    "    else:\n",
    "        return np.all(hand == 0, axis=1)\n",
    "    \n",
    "    \n",
    "def get_cards_array(card_type, num_cards):\n",
    "    \"\"\" Vector representation of the cards of one kind. \"\"\"\n",
    "    \n",
    "    cards_array = np.zeros(NUM_CARD_VALUES, dtype=np.int8)\n",
    "    cards_array[card_type] = num_cards\n",
    "    return cards_array\n",
    "    \n",
    "\n",
    "def possible_next_moves(hand, board):\n",
    "    \"\"\"\n",
    "    Returns possible next moves as a list of tuples (new hand, new board)\n",
    "    \"\"\"\n",
    "    \n",
    "    card_type_in_board = np.argmax(board)\n",
    "    num_cards_in_board = board[card_type_in_board] + board[JOKER]\n",
    "    \n",
    "    # You can always pass if it is not the initial move\n",
    "    possible_hands = np.reshape(hand, (1, NUM_CARD_VALUES))\n",
    "    possible_boards = np.reshape(board, (1, NUM_CARD_VALUES))\n",
    "    \n",
    "    if not has_already_won(hand):\n",
    "        for card_type_in_hand in range(NUM_CARD_VALUES - 1, -1, -1):\n",
    "            # You can play clean\n",
    "            if card_type_in_hand < card_type_in_board and \\\n",
    "              hand[card_type_in_hand] >= num_cards_in_board:\n",
    "                new_board = get_cards_array(card_type_in_hand, num_cards_in_board)\n",
    "                new_hand = hand - new_board\n",
    "                possible_hands = np.vstack([possible_hands, new_hand])\n",
    "                possible_boards = np.vstack([possible_boards, new_board])\n",
    "\n",
    "            # Or you can play dirty (with Joker(s))\n",
    "            if card_type_in_hand != JOKER and hand[JOKER] > 0 and \\\n",
    "              card_type_in_hand < card_type_in_board and hand[card_type_in_hand] > 0 and \\\n",
    "              hand[card_type_in_hand] + hand[JOKER] >= num_cards_in_board:\n",
    "                # Use one joker\n",
    "                if hand[card_type_in_hand] + 1 >= num_cards_in_board:\n",
    "                    joker_vec = get_cards_array(JOKER, 1)\n",
    "                    new_board = get_cards_array(card_type_in_hand, num_cards_in_board - 1) + joker_vec\n",
    "                    new_hand = hand - new_board\n",
    "                    possible_hands = np.vstack([possible_hands, new_hand])\n",
    "                    possible_boards = np.vstack([possible_boards, new_board])\n",
    "\n",
    "                # Use two jokers\n",
    "                if hand[JOKER] == 2 and num_cards_in_board > 2:\n",
    "                    joker_vec = get_cards_array(JOKER, 2)\n",
    "                    new_board = get_cards_array(card_type_in_hand, num_cards_in_board - 2) + joker_vec\n",
    "                    new_hand = hand - new_board\n",
    "                    possible_hands = np.vstack([possible_hands, new_hand])\n",
    "                    possible_boards = np.vstack([possible_boards, new_board])\n",
    "            \n",
    "    return possible_hands, possible_boards\n",
    "        \n",
    "    \n",
    "# Some tests\n",
    "assert has_already_won(np.zeros(NUM_CARD_VALUES))\n",
    "assert not has_already_won(np.ones(NUM_CARD_VALUES))\n",
    "assert np.all(has_already_won(np.zeros((2, NUM_CARD_VALUES))) == np.array([True, True]))\n",
    "assert np.all(has_already_won(np.array([[0,0,0,0,1], [0,0,0,0,0], [1,0,0,0,0]])) == np.array([False, True, False]))\n",
    "\n",
    "assert np.all(get_cards_array(1, 2) == np.array([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
    "assert np.all(get_cards_array(4, 3) == np.array([0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
    "assert not np.all(get_cards_array(4, 3) == np.array([0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
    "\n",
    "# Tests for possible moves\n",
    "h, b = possible_next_moves(np.array([0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2]),\n",
    "                           np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0]))\n",
    "assert np.all(h == np.array([[0., 2., 0., 0., 0., 0., 0., 2., 0., 2., 0., 0., 2.],\n",
    "                             [0., 2., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 2.],\n",
    "                             [0., 2., 0., 0., 0., 0., 0., 1., 0., 2., 0., 0., 1.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 2., 0., 2., 0., 0., 2.],\n",
    "                             [0., 1., 0., 0., 0., 0., 0., 2., 0., 2., 0., 0., 1.]]))\n",
    "assert np.all(b == np.array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
    "                             [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                             [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]))\n",
    "h, b = possible_next_moves(np.array([1, 2, 3, 1, 0, 0, 0, 3, 0, 4, 0, 0, 2]),\n",
    "                           np.array([0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1]))\n",
    "assert np.all(h == np.array([[1., 2., 3., 1., 0., 0., 0., 3., 0., 4., 0., 0., 2.],\n",
    "                             [1., 2., 3., 1., 0., 0., 0., 0., 0., 4., 0., 0., 2.],\n",
    "                             [1., 2., 3., 1., 0., 0., 0., 1., 0., 4., 0., 0., 1.],\n",
    "                             [1., 2., 3., 1., 0., 0., 0., 2., 0., 4., 0., 0., 0.],\n",
    "                             [1., 2., 3., 0., 0., 0., 0., 3., 0., 4., 0., 0., 0.],\n",
    "                             [1., 2., 0., 1., 0., 0., 0., 3., 0., 4., 0., 0., 2.],\n",
    "                             [1., 2., 1., 1., 0., 0., 0., 3., 0., 4., 0., 0., 1.],\n",
    "                             [1., 2., 2., 1., 0., 0., 0., 3., 0., 4., 0., 0., 0.],\n",
    "                             [1., 0., 3., 1., 0., 0., 0., 3., 0., 4., 0., 0., 1.],\n",
    "                             [1., 1., 3., 1., 0., 0., 0., 3., 0., 4., 0., 0., 0.],\n",
    "                             [0., 2., 3., 1., 0., 0., 0., 3., 0., 4., 0., 0., 0.]]))\n",
    "assert np.all(b == np.array([[0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0., 0.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
    "                             [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 2.],\n",
    "                             [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 2.],\n",
    "                             [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                             [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                             [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.],\n",
    "                             [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                             [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.],\n",
    "                             [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h, b = possible_next_moves(np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 2]),\n",
    "                           np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]))\n",
    "len(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Random Initial Game States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 2, 2, 1, 3, 0, 3, 4, 1, 3, 0],\n",
       "       [0, 1, 1, 1, 2, 1, 1, 2, 2, 4, 3, 1, 1],\n",
       "       [1, 0, 2, 1, 1, 2, 0, 2, 2, 1, 3, 4, 1],\n",
       "       [0, 0, 0, 0, 0, 2, 3, 4, 2, 1, 4, 4, 0]], dtype=int8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_PLAYERS = 4\n",
    "AVAILABLE_CARDS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 2]\n",
    "PLAYER = list(range(NUM_PLAYERS))\n",
    "\n",
    "\n",
    "def random_initial_cards():\n",
    "    \"\"\" Random initial state for the game. \"\"\"\n",
    "    \n",
    "    deck = np.array([], dtype=np.int8)\n",
    "\n",
    "    for card_type in range(NUM_CARD_VALUES):\n",
    "        deck = np.append(deck, np.array([card_type for _ in range(AVAILABLE_CARDS[card_type])]))\n",
    "    \n",
    "    np.random.shuffle(deck)\n",
    "    \n",
    "    chunk = deck.shape[0] // NUM_PLAYERS\n",
    "    remainder = deck.shape[0] % NUM_PLAYERS\n",
    "    first_player_initialized = False\n",
    "    \n",
    "    for playerIndex in range(NUM_PLAYERS):\n",
    "        beginOfChunk = playerIndex * chunk + min(playerIndex, remainder)\n",
    "        endOfChunk = (playerIndex + 1) * chunk + min(playerIndex + 1, remainder)\n",
    "        player = np.zeros(NUM_CARD_VALUES, dtype=np.int8)\n",
    "        \n",
    "        for card in deck[beginOfChunk:endOfChunk]:\n",
    "            player += get_cards_array(card, 1)\n",
    "            \n",
    "        if first_player_initialized:\n",
    "            player_initial_hands = np.vstack([player_initial_hands, player])\n",
    "        else:\n",
    "            first_player_initialized = True\n",
    "            player_initial_hands = player\n",
    "        \n",
    "    return player_initial_hands\n",
    "        \n",
    "        \n",
    "random_initial_cards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(random_initial_cards(), axis=1) == 20 * np.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.sum(random_initial_cards(), axis=1) == 20 * np.ones(NUM_PLAYERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Cards Vector for Indexing and Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_bit_offset = [\n",
    "      0,  2,  6, 10, 14, 18,  22,  25,  28,  31,  34,  36,  38,\n",
    "     39, 41, 45, 49, 53, 57,  61,  64,  67,  70,  73,  75,  77,\n",
    "     78, 80, 84, 88, 92, 96, 100, 103, 106, 109, 112, 114, 116,\n",
    "    117  # sentinel\n",
    "]\n",
    "\n",
    "def encode_card_array(card_array):\n",
    "    \"\"\"\n",
    "    Encodes a card vector into an int64.\n",
    "    | Board | Hand | Already played |\n",
    "     38   26 25  13 12             0\n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def decode_card_repr(card_repr):\n",
    "    \"\"\"\n",
    "    Decodes an int64 back to a card vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use GPU for model training\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\derfu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\derfu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\derfu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\derfu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\derfu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\derfu\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 2, 11, 11)         110       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 10, 13)         585       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                1703      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 2,412\n",
      "Trainable params: 2,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create sequential model\n",
    "network = models.Sequential()\n",
    "\n",
    "# Use to convolutional layers to group same cards\n",
    "# of a kind among the different input vectors\n",
    "network.add(layers.convolutional.Conv2D(\n",
    "    # Input rows: Already played, board, hand, action\n",
    "    input_shape=(4, 13, 1),\n",
    "    # Window size\n",
    "    kernel_size=(3, 3),\n",
    "    # Output filters\n",
    "    filters=11,\n",
    "    # Activation\n",
    "    activation='relu',\n",
    "    #data_format='channels_first'\n",
    "))\n",
    "\n",
    "network.add(layers.convolutional.Conv2D(\n",
    "    # Window size\n",
    "    kernel_size=(2, 2),\n",
    "    # Output filters\n",
    "    filters=13,\n",
    "    # Activation\n",
    "    activation='relu'\n",
    "))\n",
    "\n",
    "# Flatten convolutional layers\n",
    "network.add(layers.Flatten())\n",
    "network.add(layers.Dense(13, activation=\"relu\"))\n",
    "\n",
    "# Dropout to remove noise\n",
    "network.add(layers.Dropout(0.5))\n",
    "\n",
    "# Final dense layer for q-value\n",
    "network.add(layers.Dense(1))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss='mse', optimizer='RMSprop', metrics=['mse'])\n",
    "\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_al_ply = np.array(list(map(lambda li: [li], np.array([0,0,2,0,4,0,0,0,0,0,0,0,0]))))\n",
    "ex_brd = np.array(list(map(lambda li: [li], np.array([0,0,2,0,0,0,0,0,0,0,0,0,0]))))\n",
    "ex_hand = np.array(list(map(lambda li: [li], np.array([0,0,0,0,0,0,0,0,0,0,0,0,0]))))\n",
    "ex_action = np.array(list(map(lambda li: [li], np.array([0,2,0,0,0,0,0,0,0,0,0,0,0]))))\n",
    "ex_rew = np.array(list(map(lambda li: [li], np.array([1.]))))\n",
    "\n",
    "x = np.stack([[ex_al_ply, ex_brd, ex_hand, ex_action]], axis=0)\n",
    "y = ex_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2],[2,3]]) == np.array([[1,2],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "1/1 [==============================] - 0s 0us/step - loss: 0.0323 - mean_squared_error: 0.0323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abe5508c50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(x, y, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852979"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(x)[0, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
